\subsection{Summary}
\label{chp:study:sec:interpretation:subsec:summary}
% Answer the research question
In this section we interpreted the models' results and found out that the models perform poorly in uncovering vague requirements reliably.
We tried to comprehend and explain their predictions by applying \ac{LIME} which yielded no conclusive explanation.
After that, we took a look at the models' output tokens and their self-attention layers to find clues for the poor prediction results.
Further, we identified the simple downstream classifier of our models as potential cause.
Due to the models' architecture we suspect that transformer-based models are not capable of aggregating requirements with regards to their vagueness.

With this in mind, we can now answer our \ac{RQ} from \cref{chp:study:sec:goal}.
Due to the poor results and the concerns regarding the models' architecture we conclude that vanilla transformer-based models in their current implementation are not capable of reliably classifying requirements as vague or not-vague.
