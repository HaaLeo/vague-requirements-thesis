\chapter{Conclusion}
\label{chp:conclusion}
The modern software engineering process includes the specification of requirements.
Defining proper requirements which are understood by all stakeholders can be difficult \parencite{Lauesen:2001}.
Faults which occur during this phase cost time and money in subsequent process steps \parencite{Mendez:2016} and even result in sever project delay \parencite{Femmer:2014}.
To tackle these issues and offer possible solutions for them, the research field \ac{RE} emerged.
Until now, \ac{RE} mostly considered rule-based approaches which already lead to promising results.
Although in recent years \ac{ML} based approaches returned astonishing results on various \ac{NLP} tasks, rather little research is being undertaken in the domain of \ac{RE} using state of the art \ac{ML} approaches.
The aim of this thesis is to bridge this gap and evaluate whether and to what extent state of the art \ac{ML} based approaches are capable of detecting vague requirements.

Within this thesis we first define what we consider a \textit{vague requirement} throughout this work.
As state of the art \ac{ML} models we use transformer-based models, namely \ac{BERT}, \ac{DistilBERT} and \ac{ERNIE2.0}.
All these models are trained with supervised learning.
This technique requires an annotated dataset which, to our knowledge, was not contributed by earlier research.
Therefore, with this thesis we contribute a dataset including $2,776$ datapoints of which $589$ are labeled as vague and $2,187$ are annotated as not-vague.
The dataset is created in part via crowdsourcing and in part via manual labeling by an expert.

We then use this dataset and the models to apply transfer learning.
This means that we take a pre-trained version of each model and train it on our domain specific dataset.
With the trained models and new unseen data we generate predictions which are used to calculate the metrics precision, recall, $F_1$ score and \ac{AP}.
The models' maximum values for these metrics are $45\%$ precision, $85\%$ recall, $50\%$ $F_1$ score and $46\%$ \ac{AP}.
Comparing these results with other rule-based approaches yields that approaches introduced in this thesis perform worse.
In order to verify this conclusion we take a look at other transformer-based approaches from different domains.
All those approaches return rather poor results for the vanilla implementation of \ac{BERT} using a simple downstream classifier.
Most of the approaches are able to significantly enhance the models' performance by using a larger dataset or a more sophisticated downstream classification strategy.

Our research shows that \ac{ML} approaches based on pre-trained transformers are no plug-and-play solutions to revolutionize the field of \ac{RE}.
Quite to the contrary, these approaches perform even worse than traditional approaches.
We conclude that transformers in their examined versions are worse in detecting poor requirements than traditional approaches.
Although this result appears sobering at first glance, it offers interesting follow-up questions as opportunity for future research which can use the presented results as baseline.
It remains exciting how transformers and future \ac{ML} approaches in general will perform on \ac{NLP} tasks of the \ac{RE} domain.
