\subsection{Average Precision}
\label{chp:fundamentals:sec:metrics:subsec:average_precision}

Due to the previously mentioned trade-off between recall and precision both of those metrics must be considered when optimizing a model for a task.
One metric which considers recall as well as precision is \ac{AP}.
\Textcite{Zhu:2004} defines it as the following:

\begin{equation}\label{eq:average_precision}
    AP = \sum_{i=1}^n {p(i)\Delta r(i)}
\end{equation}

Where $p(i)$ is the precision taking into account the first $i$ elements.
$\Delta r(i)$ indicates the the recall change from the $i-1$th element to the $i$th item.
With this metric the order of the sequence is crucial.
An algorithm which manages to sort a sequence of elements that all relevant items are listed first will achieve higher AP than an algorithm that performs poorly on the sorting task.

Let us consider the following example.
An algorithm was trained to return all relevant items from a dataset.
Given an unseen dataset of 5 items the model returns the following sorted sequence given in \cref{fig:metrics:average_precision:sample}.
The sequence is sorted in descending order, meaning the elements which are considered as most relevant by the algorithm are inserted first.

\begin{figure}[htpb]
    \centering
    \def\svgwidth{\columnwidth}
    \input{figures/metrics/Average_Precision.pdf_tex}
    \caption[Example Sequence]{A sorted example sequence returned by some algorithm.}\label{fig:metrics:average_precision:sample}
\end{figure}

Now we can calculate the \ac{AP} according to \cref{eq:average_precision}:
\begin{equation}
    \begin{aligned}
        AP &= \sum_{i=1}^n {p(i)\Delta r(i)}\\
        &= \frac{1}{1} \cdot \frac{1}{3} + \frac{1}{2} \cdot 0 + \frac{2}{3} \cdot \frac{1}{3} + \frac{3}{4} \cdot \frac{1}{3} + \frac{3}{5} \cdot 0\\
        &=  (\frac{1}{1} + \frac{2}{3}  + \frac{3}{4}) \cdot \frac{1}{3}\\
        &\approx 0.81
    \end{aligned}
\end{equation}
