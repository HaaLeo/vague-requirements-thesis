\subsection{Average Precision}
\label{chp:fundamentals:sec:metrics:subsec:average_precision}

Due to the previously mentioned trade-off between recall and precision both of those metrics should be considered when optimizing a model for a task.
One metric which considers recall as well as precision is \ac{AP}.

\subsubsection{Definition}
\label{chp:fundamentals:sec:metrics:subsec:average_precision:definition}

\Textcite{Zhu:2004} defines it as the following:

\begin{equation}\label{eq:average_precision}
    AP = \sum_{i=1}^n {p(i)\Delta r(i)}
\end{equation}

Where $p(i)$ is the precision taking into account the first $i$ elements and $\Delta r(i)$ indicates the the recall change from the $i-1$th to the $i$th item.
With this metric the order of the sequence is crucial.
An algorithm which manages to sort a sequence of elements in a way that all relevant items are listed first achieves higher AP than an algorithm which performs poorly on the sorting task.

Let us consider the following example.
An algorithm was trained to return all relevant items from a dataset.
Given an unseen dataset of five items the model returns the following sorted sequence given in \cref{fig:metrics:average_precision:sample}.
The sequence is sorted in descending order, meaning the elements which the algorithm classifies as relevant with most confidence, are inserted first.
Consequently, in the example below the algorithm falsely classifies the second and fifth item as relevant.

\begin{figure}[htpb]
    \centering
    \def\svgwidth{\columnwidth}
    \input{figures/metrics/Average_Precision.pdf_tex}
    \caption[Example Sequence]{A sorted example sequence returned by some algorithm.}\label{fig:metrics:average_precision:sample}
\end{figure}

The sequence shown in \cref{fig:metrics:average_precision:sample} contains a total of three relevant items.
Following \textcite{Zhu:2004}, this yields a recall change $\Delta r(i)=\frac{1}{3}$ for a relevant item $i$ and $\Delta r(i)=0$ for an irrelevant one.
Now we can calculate the \ac{AP} according to \cref{eq:average_precision}:
\begin{equation}
    \begin{aligned}
        AP &= \sum_{i=1}^n {p(i)\Delta r(i)}\\
        &= \frac{1}{1} \cdot \frac{1}{3} + \frac{1}{2} \cdot 0 + \frac{2}{3} \cdot \frac{1}{3} + \frac{3}{4} \cdot \frac{1}{3} + \frac{3}{5} \cdot 0\\
        &=  (\frac{1}{1} + \frac{2}{3}  + \frac{3}{4}) \cdot \frac{1}{3}\\
        &\approx 0.81
    \end{aligned}
\end{equation}

\subsubsection{Interpretation}
\label{chp:fundamentals:sec:metrics:subsec:average_precision:interpretation}
The overall interpretation of \ac{AP} is intuitive: The more relevant items are ranked at the top of the returned sequence the higher is the \ac{AP} value.
However, in contrast to precision and recall, it is more difficult to judge whether the retrieved value for \ac{AP} is "good" or "bad".
Should we consider a system which yields $\ac{AP}=0.66$ as good?
In this part we want to address this issue and provide a tangible interpretation of the \ac{AP} value.

First we want to take a look at different example sequences and their corresponding \ac{AP} values.
We then derive an intuitive explanation for these example sequences which helps to judge \ac{AP} in general.
Let us consider two example sequences \textit{sequence 1} and \textit{sequence 2} shown in \cref{fig:metrics:average_precision:interpreation:sample}.

\begin{figure}[htpb]
    \centering
    \def\svgwidth{\columnwidth}
    \input{figures/metrics/Average_Precision_Example.pdf_tex}
    \caption[Two Example Sequences]{Two example sequences taken from \textcite{Tapaswi:2012}.}\label{fig:metrics:average_precision:interpreation:sample}
\end{figure}

For the first sequence we observe that \textit{every third} top ranked item is relevant whereas in the second sequence \textit{every second} item is.
We can now calculate the \ac{AP} for both sequences according to \cref{eq:average_precision} which yields $\ac{AP}_1= \frac{1}{3}$ for the first sequence and $\ac{AP}_2= \frac{1}{2}$ for the second one.
With the sequences above and their corresponding \acp{AP} $\ac{AP}_1$ and $\ac{AP}_2$ we can now conclude that an $\ac{AP}=\frac{1}{j}$ indicates that every $j$th item is relevant \parencite{Tapaswi:2012}.
With this in mind an $\ac{AP}=0.66$ is rather good, because approximately every $1.5$th item of the top ranked ones is relevant, whereas with an example $\ac{AP}=0.2$ only every fifth item is relevant.
