\section{Downstream Classifier}
\label{chp:future_work:sec:downstream_classifier}
Our research indicates that after a transformer encodes each requirement, the resulting encodings are not linear separable.
However, this does not mean that the datapoints are not separable at all.
To examine whether the resulting encodings are separable, one should consider advanced techniques.
One possibility is to apply feature transformations to transform the features to another space where the datapoints indeed are separable.
To achieve this, one should consider a more complex \ac{NN} architecture as downstream classifier.
For instance using more layers with more trainable parameters to capture the complexity of the classification task.
Another way is to incorporate not only the first [CLS] output token of the transformers, but further output token like \textcite{Gao:2019} did.
There are various complexer choices for a downstream classifier.
Future research should examine whether and to what extent the use of more complex downstream classifier enhances the classification results.
